projects:

    deepfool:
        name:         DeepFool
        description:  Simple algorithm to find the minimum adversarial perturbations in deep networks
        layman_desc: >
            DeepFool is a simple algorithm to find the minimum perturbations
            needed in deep networks to change the outcome of its decision.
        code:
            type: Lab GitHub
            url:  https://github.com/LTS4/DeepFool
            date_last_commit: 2018-09-07
        contacts:
            - name:   Seyed Moosavi
              email:  seyed.moosavi@epfl.ch
        tags:
            - Machine Learning
            - Deep Networks
            - Adversarial
        language: MatLab, Python
        type: Application
        information:
            - type:   Paper
              title:  'DeepFool: a simple and accurate method to fool deep neural networks'
              url:    https://arxiv.org/abs/1511.04599
        date_added: 2019-03-18
        date_updated: 2020-02-06

    manifool:
        name:         ManiFool
        description:  Algorithm for evaluating the invariance properties of deep networks
        code:
            type: Personal GitHub
            url:  https://github.com/moosavism/ManiFool
            date_last_commit: 2018-01-24
        contacts:
            - name:   Seyed Moosavi
              email:  seyed.moosavi@epfl.ch
        tags:
            - Machine Learning
            - Deep Networks
        language: Python
        type: Application
        information:
            - type:   Paper
              title:  'Geometric robustness of deep networks: analysis and improvement'
              url:    https://arxiv.org/abs/1711.09115
        date_added: 2019-03-18
        date_updated: 2020-02-06

    sparsefool:
        name:         SparseFool
        description:  Geometry-inspired sparse attack on deep networks
        layman_desc: >
            Deep Neural Networks have achieved extraordinary results on image
            classification tasks, but have been shown to be vulnerable to attacks
            with carefully crafted perturbations of the input data. Although most
            attacks usually change values of many imageâ€™s pixels, it has been
            shown that deep networks are also vulnerable to sparse alterations
            of the input.
            SparseFool implements an efficient algorithm to compute and control
            sparse alterations.
        code:
            type: Lab GitHub
            url:  https://github.com/LTS4/SparseFool
            date_last_commit: 2019-06-05
        contacts:
            - name:   Apostolos Modas
              email:  apostolos.modas@epfl.ch
        tags:
            - Machine Learning
            - Deep Networks
        language: Python
        type: Application
        information:
            - type:   Paper
              title:  'SparseFool: a few pixels make a big difference'
              url:    https://arxiv.org/abs/1811.02248
        date_added: 2019-09-04
        date_updated: 2019-09-04

    foolbox:
        name: Foolbox 3.0
        description: 'Python toolbox to create adversarial examples that fool neural networks in PyTorch, TensorFlow, and JAX'
        layman_desc: >
            Neural networks need to be trained with many examples. By providing
            carefully crafted samples, an adversary can attack the system and
            lead the neural network to change the decisions it takes, for
            example by making a STOP sign be falsely interpreted as a speed
            limit.
            Foolbox comes with a large collection of adversarial attacks, both
            gradient-based (white-box) as well as decision-based and
            score-based (black-box), providing users with powerful tools to
            evaluate models and determine how robust they are to such attacks.
        url: https://foolbox.jonasrauber.de/
        code:
            type: Lab GitHub
            url: https://github.com/bethgelab/foolbox
            date_last_commit: 2020-03-22
        doc: https://foolbox.readthedocs.io/
        contacts:
            - name: Jonas Rauber
              email: jonas.rauber@bethgelab.org
              url:  https://github.com/jonasrauber
        tags:
            - Machine Learning
            - Deep Networks
            - Attack
        language: Python
        type: Application
        license:    MIT
        information:
            - type: Paper
              title: 'Foolbox: A Python toolbox to benchmark the robustness of machine learning models'
              url: https://arxiv.org/abs/1707.04131
        date_added: 2020-02-06
        date_updated: 2020-03-23
        maturity: 0

    universal:
        name:         Universal
        description:  Universal adversarial perturbations
        layman_desc: >
            Proposing a universal (image-agnostic) and very small perturbation
            vector that causes natural images to be misclassified with high
            probability in a deep neuronal network.
        url:          https://arxiv.org/pdf/1610.08401.pdf
        code:
            type: Lab GitHub
            url:  https://github.com/LTS4/universal
            date_last_commit: 2017-10-23
        contacts:
            - name:   Seyed Moosavi
              email:  seyed.moosavi@epfl.ch
        tags:
            - Machine Learning
            - Deep Networks
            - Perturbations
        language: MatLab, Python
        type: Application
        information:
            - type:   Paper
              title:  'Universal adversarial perturbations'
              url:    https://arxiv.org/pdf/1610.08401.pdf
        date_added: 2019-03-18
        date_updated: 2020-02-06
